{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6c2505",
   "metadata": {},
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169c884",
   "metadata": {},
   "source": [
    "vocab_size (int, optional, defaults to 50265) — Vocabulary size of the PEGASUS model. Defines the number of different tokens that can be represented by the inputs_ids passed when calling PegasusModel or TFPegasusModel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d4764",
   "metadata": {},
   "source": [
    "d_model (int, optional, defaults to 1024) — Dimensionality of the layers and the pooler layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94f9ed",
   "metadata": {},
   "source": [
    "encoder_layers (int, optional, defaults to 12) — Number of encoder layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23926ce2",
   "metadata": {},
   "source": [
    "decoder_layers (int, optional, defaults to 12) — Number of decoder layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6713876",
   "metadata": {},
   "source": [
    "encoder_attention_heads (int, optional, defaults to 16) — Number of attention heads for each attention layer in the Transformer encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc790077",
   "metadata": {},
   "source": [
    "decoder_attention_heads (int, optional, defaults to 16) — Number of attention heads for each attention layer in the Transformer decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557168b7",
   "metadata": {},
   "source": [
    "decoder_ffn_dim (int, optional, defaults to 4096) — Dimensionality of the “intermediate” (often named feed-forward) layer in decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3690702",
   "metadata": {},
   "source": [
    "encoder_ffn_dim (int, optional, defaults to 4096) — Dimensionality of the “intermediate” (often named feed-forward) layer in decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b4e91",
   "metadata": {},
   "source": [
    "activation_function (str or function, optional, defaults to \"gelu\") — The non-linear activation function (function or string) in the encoder and pooler. If string, \"gelu\", \"relu\", \"silu\" and \"gelu_new\" are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fb835",
   "metadata": {},
   "source": [
    "dropout (float, optional, defaults to 0.1) — The dropout probability for all fully connected layers in the embeddings, encoder, and pooler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ccf3",
   "metadata": {},
   "source": [
    "attention_dropout (float, optional, defaults to 0.0) — The dropout ratio for the attention probabilities.\n",
    "\n",
    "activation_dropout (float, optional, defaults to 0.0) — The dropout ratio for activations inside the fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c6d98",
   "metadata": {},
   "source": [
    "classifier_dropout (float, optional, defaults to 0.0) — The dropout ratio for classifier. \n",
    "\n",
    "max_position_embeddings (int, optional, defaults to 1024) — The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32926a39",
   "metadata": {},
   "source": [
    "init_std (float, optional, defaults to 0.02) — The standard deviation of the truncated_normal_initializer for initializing all weight matrices. encoder_layerdrop — (float, optional, defaults to 0.0): The LayerDrop probability for the encoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556) for more details. decoder_layerdrop — (float, optional, defaults to 0.0): The LayerDrop probability for the decoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556) for more details.\n",
    "\n",
    "\n",
    "scale_embedding (bool, optional, defaults to False) — Scale embeddings by diving by sqrt(d_model).\n",
    "\n",
    "\n",
    "use_cache (bool, optional, defaults to True) — Whether or not the model should return the last key/values attentions (not used by all models)\n",
    "\n",
    "\n",
    "forced_eos_token_id (int, optional, defaults to 1) — The id of the token to force as the last generated token when max_length is reached. Usually set to eos_token_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusModel, PegasusConfig\n",
    "\n",
    "# Initializing a PEGASUS google/pegasus-large style configuration\n",
    "configuration = PegasusConfig()\n",
    "\n",
    "# Initializing a model from the google/pegasus-large style configuration\n",
    "model = PegasusModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa730ab",
   "metadata": {},
   "source": [
    "PARAMETERS\n",
    "\n",
    "( vocab_size = 50265max_position_embeddings = 1024encoder_layers = 12encoder_ffn_dim = 4096encoder_attention_heads = 16decoder_layers = 12decoder_ffn_dim = 4096decoder_attention_heads = 16encoder_layerdrop = 0.0decoder_layerdrop = 0.0use_cache = Trueis_encoder_decoder = Trueactivation_function = 'gelu'd_model = 1024dropout = 0.1attention_dropout = 0.0activation_dropout = 0.0init_std = 0.02decoder_start_token_id = 0classifier_dropout = 0.0scale_embedding = Falsepad_token_id = 0eos_token_id = 1forced_eos_token_id = 1**kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c09249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
